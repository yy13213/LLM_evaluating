"""
å¤§è¯­è¨€æ¨¡å‹ç»¼åˆèƒ½åŠ›æµ‹è¯„å¹³å°
================================
ç”¨äºæµ‹è¯•å’Œæ¯”è¾ƒä¸åŒå¤§è¯­è¨€æ¨¡å‹åœ¨å„ç»´åº¦ä¸Šçš„è¡¨ç°
"""

import streamlit as st
import json
import os
from datetime import datetime
from pathlib import Path
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="LLM æµ‹è¯„å¹³å°",
    page_icon="ğŸ§ª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&family=JetBrains+Mono&display=swap');
    
    :root {
        --primary-color: #6366f1;
        --secondary-color: #8b5cf6;
        --accent-color: #f59e0b;
        --bg-dark: #0f172a;
        --bg-card: #1e293b;
        --text-primary: #f1f5f9;
        --text-secondary: #94a3b8;
        --border-color: #334155;
        --success-color: #22c55e;
        --warning-color: #eab308;
        --error-color: #ef4444;
    }
    
    .main {
        background: linear-gradient(135deg, #0f172a 0%, #1e1b4b 50%, #0f172a 100%);
    }
    
    .stApp {
        background: linear-gradient(135deg, #0f172a 0%, #1e1b4b 50%, #0f172a 100%);
    }
    
    h1, h2, h3 {
        font-family: 'Noto Sans SC', sans-serif !important;
        color: var(--text-primary) !important;
    }
    
    .main-title {
        background: linear-gradient(90deg, #6366f1, #8b5cf6, #a855f7);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 2.5rem !important;
        font-weight: 700 !important;
        text-align: center;
        padding: 1rem 0;
    }
    
    .question-card {
        background: linear-gradient(145deg, #1e293b, #334155);
        border: 1px solid #475569;
        border-radius: 16px;
        padding: 1.5rem;
        margin: 1rem 0;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
    }
    
    .question-header {
        display: flex;
        align-items: center;
        gap: 0.75rem;
        margin-bottom: 1rem;
    }
    
    .question-id {
        background: linear-gradient(135deg, #6366f1, #8b5cf6);
        color: white;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-weight: 600;
        font-size: 0.875rem;
    }
    
    .dimension-badge {
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-size: 0.75rem;
        font-weight: 500;
    }
    
    .dim-logic { background: #3b82f6; color: white; }
    .dim-coding { background: #22c55e; color: white; }
    .dim-language { background: #f59e0b; color: white; }
    .dim-tool_use { background: #8b5cf6; color: white; }
    .dim-safety { background: #ef4444; color: white; }
    
    .model-card {
        background: linear-gradient(145deg, #1e293b, #0f172a);
        border: 1px solid #475569;
        border-radius: 12px;
        padding: 1rem;
        margin: 0.5rem 0;
        transition: all 0.3s ease;
    }
    
    .model-card:hover {
        border-color: #6366f1;
        box-shadow: 0 0 20px rgba(99, 102, 241, 0.2);
    }
    
    .copy-btn {
        background: linear-gradient(135deg, #6366f1, #8b5cf6) !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 0.5rem 1rem !important;
        font-weight: 500 !important;
        cursor: pointer !important;
        transition: all 0.3s ease !important;
    }
    
    .copy-btn:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(99, 102, 241, 0.4);
    }
    
    .stats-card {
        background: linear-gradient(145deg, #1e293b, #334155);
        border: 1px solid #475569;
        border-radius: 12px;
        padding: 1.25rem;
        text-align: center;
    }
    
    .stats-number {
        font-size: 2rem;
        font-weight: 700;
        background: linear-gradient(90deg, #6366f1, #a855f7);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    .stats-label {
        color: var(--text-secondary);
        font-size: 0.875rem;
    }
    
    .sidebar .stSelectbox label {
        color: var(--text-primary) !important;
    }
    
    code {
        font-family: 'JetBrains Mono', monospace !important;
        background: #1e293b !important;
        padding: 0.125rem 0.375rem !important;
        border-radius: 4px !important;
    }
    
    .stTextArea textarea {
        background: #1e293b !important;
        border: 1px solid #475569 !important;
        border-radius: 8px !important;
        color: var(--text-primary) !important;
        font-family: 'Noto Sans SC', sans-serif !important;
    }
    
    .stTextArea textarea:focus {
        border-color: #6366f1 !important;
        box-shadow: 0 0 0 2px rgba(99, 102, 241, 0.2) !important;
    }
    
    .success-message {
        background: linear-gradient(135deg, #166534, #15803d);
        border: 1px solid #22c55e;
        border-radius: 8px;
        padding: 1rem;
        color: white;
    }
    
    .stButton button {
        background: linear-gradient(135deg, #6366f1, #8b5cf6) !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        font-weight: 500 !important;
        transition: all 0.3s ease !important;
    }
    
    .stButton button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 4px 12px rgba(99, 102, 241, 0.4) !important;
    }
    
    .answer-preview {
        background: #0f172a;
        border: 1px solid #334155;
        border-radius: 8px;
        padding: 1rem;
        max-height: 200px;
        overflow-y: auto;
        font-size: 0.875rem;
        color: var(--text-secondary);
    }
    
    .score-badge {
        display: inline-block;
        padding: 0.25rem 0.75rem;
        border-radius: 20px;
        font-weight: 600;
        font-size: 0.875rem;
    }
    
    .score-5 { background: #22c55e; color: white; }
    .score-4 { background: #84cc16; color: white; }
    .score-3 { background: #eab308; color: black; }
    .score-2 { background: #f97316; color: white; }
    .score-1 { background: #ef4444; color: white; }
    .score-0 { background: #64748b; color: white; }
    
    .leaderboard-row {
        background: linear-gradient(145deg, #1e293b, #334155);
        border: 1px solid #475569;
        border-radius: 8px;
        padding: 0.75rem 1rem;
        margin: 0.5rem 0;
        display: flex;
        justify-content: space-between;
        align-items: center;
    }
    
    .rank-1 { border-left: 4px solid #ffd700; }
    .rank-2 { border-left: 4px solid #c0c0c0; }
    .rank-3 { border-left: 4px solid #cd7f32; }
</style>
""", unsafe_allow_html=True)

# æ•°æ®æ–‡ä»¶è·¯å¾„
QUESTIONS_FILE = "questions.json"
MODELS_FILE = "models.json"
ANSWERS_FILE = "answers.json"
SCORING_RUBRIC_FILE = "scoring_rubric.json"

# ç»´åº¦åç§°æ˜ å°„
DIMENSION_NAMES = {
    "logic": "é€»è¾‘æ¨ç†ä¸æ•°å­¦",
    "coding": "ä»£ç ä¸æŠ€æœ¯èƒ½åŠ›",
    "language": "è¯­è¨€ç†è§£ä¸åˆ›ä½œ",
    "tool_use": "å·¥å…·è°ƒç”¨ä¸æ ¼å¼åŒ–",
    "safety": "å®‰å…¨ã€ä¼¦ç†ä¸å¹»è§‰"
}

DIMENSION_ICONS = {
    "logic": "ğŸ§®",
    "coding": "ğŸ’»",
    "language": "âœï¸",
    "tool_use": "ğŸ”§",
    "safety": "ğŸ›¡ï¸"
}

# æ¯é¢˜æ»¡åˆ†
SCORE_PER_QUESTION = 5
TOTAL_QUESTIONS = 20
MAX_TOTAL_SCORE = SCORE_PER_QUESTION * TOTAL_QUESTIONS  # 100åˆ†


def load_json(file_path):
    """åŠ è½½JSONæ–‡ä»¶"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return None
    except json.JSONDecodeError:
        st.error(f"JSONæ–‡ä»¶æ ¼å¼é”™è¯¯: {file_path}")
        return None


def save_json(file_path, data):
    """ä¿å­˜JSONæ–‡ä»¶"""
    with open(file_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def load_answers():
    """åŠ è½½ç­”æ¡ˆæ•°æ®"""
    data = load_json(ANSWERS_FILE)
    if data is None:
        data = {
            "meta": {
                "title": "æ¨¡å‹å›ç­”è®°å½•",
                "version": "1.0",
                "created_at": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat()
            },
            "answers": []
        }
        save_json(ANSWERS_FILE, data)
    return data


def save_answer(question_id, model_id, answer_text):
    """ä¿å­˜å•ä¸ªç­”æ¡ˆ"""
    data = load_answers()
    
    # æŸ¥æ‰¾æ˜¯å¦å·²æœ‰è¯¥è®°å½•
    existing_idx = None
    for idx, ans in enumerate(data["answers"]):
        if ans["question_id"] == question_id and ans["model_id"] == model_id:
            existing_idx = idx
            break
    
    answer_record = {
        "question_id": question_id,
        "model_id": model_id,
        "answer": answer_text,
        "timestamp": datetime.now().isoformat(),
        "score": None,
        "comment": None
    }
    
    if existing_idx is not None:
        # ä¿ç•™åŸæœ‰åˆ†æ•°
        if data["answers"][existing_idx].get("score") is not None:
            answer_record["score"] = data["answers"][existing_idx]["score"]
            answer_record["comment"] = data["answers"][existing_idx].get("comment")
        data["answers"][existing_idx] = answer_record
    else:
        data["answers"].append(answer_record)
    
    data["meta"]["last_updated"] = datetime.now().isoformat()
    save_json(ANSWERS_FILE, data)
    return True


def save_score(question_id, model_id, score, comment=None):
    """ä¿å­˜è¯„åˆ†"""
    data = load_answers()
    
    for ans in data["answers"]:
        if ans["question_id"] == question_id and ans["model_id"] == model_id:
            ans["score"] = score
            ans["comment"] = comment
            ans["scored_at"] = datetime.now().isoformat()
            break
    
    data["meta"]["last_updated"] = datetime.now().isoformat()
    save_json(ANSWERS_FILE, data)
    return True


def get_answer(question_id, model_id):
    """è·å–æŒ‡å®šé—®é¢˜å’Œæ¨¡å‹çš„ç­”æ¡ˆ"""
    data = load_answers()
    for ans in data["answers"]:
        if ans["question_id"] == question_id and ans["model_id"] == model_id:
            return ans
    return None


def get_model_scores(model_id):
    """è·å–æ¨¡å‹çš„æ‰€æœ‰è¯„åˆ†"""
    data = load_answers()
    scores = {}
    for ans in data["answers"]:
        if ans["model_id"] == model_id and ans.get("score") is not None:
            scores[ans["question_id"]] = ans["score"]
    return scores


def get_all_scores():
    """è·å–æ‰€æœ‰è¯„åˆ†æ•°æ®"""
    data = load_answers()
    questions_data = load_json(QUESTIONS_FILE)
    models_data = load_json(MODELS_FILE)
    
    if not questions_data or not models_data:
        return {}
    
    scores = {}
    for model in models_data["models"]:
        model_id = model["id"]
        scores[model_id] = {
            "name": model["name"],
            "icon": model["icon"],
            "scores": {},
            "total": 0,
            "answered": 0,
            "scored": 0
        }
        
        for ans in data["answers"]:
            if ans["model_id"] == model_id:
                scores[model_id]["answered"] += 1
                if ans.get("score") is not None:
                    scores[model_id]["scores"][ans["question_id"]] = ans["score"]
                    scores[model_id]["total"] += ans["score"]
                    scores[model_id]["scored"] += 1
    
    return scores


def get_statistics():
    """è·å–ç»Ÿè®¡æ•°æ®"""
    questions_data = load_json(QUESTIONS_FILE)
    models_data = load_json(MODELS_FILE)
    answers_data = load_answers()
    
    total_questions = len(questions_data["questions"]) if questions_data else 0
    total_models = len(models_data["models"]) if models_data else 0
    total_answers = len(answers_data["answers"])
    total_possible = total_questions * total_models
    completion_rate = (total_answers / total_possible * 100) if total_possible > 0 else 0
    
    # ç»Ÿè®¡å·²è¯„åˆ†æ•°é‡
    scored_count = sum(1 for ans in answers_data["answers"] if ans.get("score") is not None)
    scoring_rate = (scored_count / total_answers * 100) if total_answers > 0 else 0
    
    return {
        "total_questions": total_questions,
        "total_models": total_models,
        "total_answers": total_answers,
        "completion_rate": completion_rate,
        "scored_count": scored_count,
        "scoring_rate": scoring_rate
    }


def render_sidebar():
    """æ¸²æŸ“ä¾§è¾¹æ """
    with st.sidebar:
        st.markdown("## ğŸ§ª LLM æµ‹è¯„å¹³å°")
        st.markdown("---")
        
        # å¯¼èˆª
        page = st.radio(
            "ğŸ“ å¯¼èˆª",
            ["ğŸ  é¦–é¡µ", "ğŸ“ é¢˜ç›®æµ‹è¯„", "â­ è¯„åˆ†æ‰“åˆ†", "ğŸ“Š ç»“æœå±•ç¤º", "ğŸ“‹ æ•°æ®æŸ¥çœ‹", "âš™ï¸ è®¾ç½®"],
            label_visibility="collapsed"
        )
        
        st.markdown("---")
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = get_statistics()
        st.markdown("### ğŸ“ˆ ç»Ÿè®¡æ¦‚è§ˆ")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("é¢˜ç›®æ•°", stats["total_questions"])
            st.metric("å·²ç­”é¢˜", stats["total_answers"])
        with col2:
            st.metric("æ¨¡å‹æ•°", stats["total_models"])
            st.metric("å·²è¯„åˆ†", stats["scored_count"])
        
        st.markdown("---")
        st.markdown("### ğŸ”— æ¨¡å‹é“¾æ¥")
        models_data = load_json(MODELS_FILE)
        if models_data:
            for model in models_data["models"][:5]:
                st.markdown(f"{model['icon']} [{model['name']}]({model['url']})")
        
        return page


def render_home():
    """æ¸²æŸ“é¦–é¡µ"""
    st.markdown('<h1 class="main-title">ğŸ§ª å¤§è¯­è¨€æ¨¡å‹ç»¼åˆèƒ½åŠ›æµ‹è¯„å¹³å°</h1>', unsafe_allow_html=True)
    
    st.markdown("""
    <div style="text-align: center; color: #94a3b8; margin-bottom: 2rem;">
        æµ‹è¯•å¹¶æ¯”è¾ƒä¸åŒå¤§è¯­è¨€æ¨¡å‹åœ¨é€»è¾‘æ¨ç†ã€ä»£ç èƒ½åŠ›ã€è¯­è¨€åˆ›ä½œã€å·¥å…·è°ƒç”¨å’Œå®‰å…¨æ€§ç­‰ç»´åº¦çš„è¡¨ç°
    </div>
    """, unsafe_allow_html=True)
    
    # ç»Ÿè®¡å¡ç‰‡
    stats = get_statistics()
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="stats-card">
            <div class="stats-number">{stats['total_questions']}</div>
            <div class="stats-label">ğŸ“‹ æµ‹è¯•é¢˜ç›®</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="stats-card">
            <div class="stats-number">{stats['total_models']}</div>
            <div class="stats-label">ğŸ¤– å‚è¯„æ¨¡å‹</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="stats-card">
            <div class="stats-number">{stats['total_answers']}</div>
            <div class="stats-label">âœ… å·²æ”¶é›†ç­”æ¡ˆ</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="stats-card">
            <div class="stats-number">{stats['scored_count']}</div>
            <div class="stats-label">â­ å·²è¯„åˆ†</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # è¯„åˆ†æ ‡å‡†è¯´æ˜
    st.markdown("### ğŸ“ è¯„åˆ†æ ‡å‡†")
    st.markdown("""
    | åˆ†æ•° | ç­‰çº§ | æè¿° |
    |------|------|------|
    | **5åˆ†** | å®Œç¾ | å®Œæ•´æ­£ç¡®ï¼Œé€»è¾‘æ¸…æ™°ï¼Œæœ‰æ·±åº¦åˆ†æ |
    | **4åˆ†** | ä¼˜ç§€ | åŸºæœ¬æ­£ç¡®ï¼Œæœ‰å°ç‘•ç–µï¼Œåˆ†æè¾ƒå®Œæ•´ |
    | **3åˆ†** | è‰¯å¥½ | ä¸»è¦éƒ¨åˆ†æ­£ç¡®ï¼Œæœ‰æ˜æ˜¾é—æ¼æˆ–å°é”™è¯¯ |
    | **2åˆ†** | åŠæ ¼ | éƒ¨åˆ†æ­£ç¡®ï¼Œæœ‰è¾ƒå¤§é”™è¯¯æˆ–é‡è¦é—æ¼ |
    | **1åˆ†** | ä¸åŠæ ¼ | ä»…å°‘éƒ¨åˆ†æ­£ç¡®ï¼Œå¤§éƒ¨åˆ†é”™è¯¯ |
    | **0åˆ†** | é”™è¯¯ | å®Œå…¨é”™è¯¯æˆ–æœªä½œç­” |
    """)
    
    st.info(f"ğŸ“Š **æ€»åˆ†è®¡ç®—**: æ¯é¢˜æ»¡åˆ† {SCORE_PER_QUESTION} åˆ† Ã— {TOTAL_QUESTIONS} é¢˜ = **{MAX_TOTAL_SCORE} åˆ†**")
    
    st.markdown("---")
    
    # ç»´åº¦ä»‹ç»
    st.markdown("### ğŸ“ æµ‹è¯„ç»´åº¦")
    
    questions_data = load_json(QUESTIONS_FILE)
    if questions_data:
        cols = st.columns(5)
        for idx, dim in enumerate(questions_data["meta"]["dimensions"]):
            with cols[idx]:
                st.markdown(f"""
                <div class="stats-card">
                    <div style="font-size: 2rem;">{DIMENSION_ICONS.get(dim['id'], 'ğŸ“Œ')}</div>
                    <div style="font-weight: 600; color: #f1f5f9; margin: 0.5rem 0;">{dim['name']}</div>
                    <div style="font-size: 0.75rem; color: #94a3b8;">{len(dim['questions'])} é“é¢˜</div>
                </div>
                """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # ä½¿ç”¨è¯´æ˜
    st.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
    st.markdown("""
    1. **ğŸ“ é¢˜ç›®æµ‹è¯„**: å¤åˆ¶é¢˜ç›®ï¼Œå‰å¾€æ¨¡å‹å®˜ç½‘è·å–ç­”æ¡ˆï¼Œç²˜è´´å›å¹³å°
    2. **â­ è¯„åˆ†æ‰“åˆ†**: æ ¹æ®è¯„åˆ†æ ‡å‡†ä¸ºæ¯ä¸ªç­”æ¡ˆæ‰“åˆ†ï¼ˆ0-5åˆ†ï¼‰
    3. **ğŸ“Š ç»“æœå±•ç¤º**: æŸ¥çœ‹æ’è¡Œæ¦œã€é›·è¾¾å›¾ã€ç»´åº¦å¯¹æ¯”ç­‰å¯è§†åŒ–åˆ†æ
    4. **ğŸ“‹ æ•°æ®æŸ¥çœ‹**: å¯¼å‡ºæ•°æ®ï¼ŒæŸ¥çœ‹ç­”æ¡ˆå¯¹æ¯”
    """)


def render_questions():
    """æ¸²æŸ“é¢˜ç›®æµ‹è¯„é¡µé¢"""
    st.markdown('<h1 class="main-title">ğŸ“ é¢˜ç›®æµ‹è¯„</h1>', unsafe_allow_html=True)
    
    questions_data = load_json(QUESTIONS_FILE)
    models_data = load_json(MODELS_FILE)
    
    if not questions_data or not models_data:
        st.error("æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶")
        return
    
    # ç­›é€‰å™¨
    col1, col2, col3 = st.columns(3)
    
    with col1:
        dimension_options = ["å…¨éƒ¨"] + [d["name"] for d in questions_data["meta"]["dimensions"]]
        selected_dimension = st.selectbox("ğŸ·ï¸ é€‰æ‹©ç»´åº¦", dimension_options)
    
    with col2:
        model_options = ["å…¨éƒ¨"] + [m["name"] for m in models_data["models"]]
        selected_model = st.selectbox("ğŸ¤– é€‰æ‹©æ¨¡å‹", model_options)
    
    with col3:
        question_ids = ["å…¨éƒ¨"] + [str(q["id"]) for q in questions_data["questions"]]
        selected_question = st.selectbox("ğŸ“‹ é€‰æ‹©é¢˜å·", question_ids)
    
    st.markdown("---")
    
    # è¿‡æ»¤é¢˜ç›®
    filtered_questions = questions_data["questions"]
    
    if selected_dimension != "å…¨éƒ¨":
        dim_id = None
        for d in questions_data["meta"]["dimensions"]:
            if d["name"] == selected_dimension:
                dim_id = d["id"]
                break
        if dim_id:
            filtered_questions = [q for q in filtered_questions if q["dimension"] == dim_id]
    
    if selected_question != "å…¨éƒ¨":
        filtered_questions = [q for q in filtered_questions if str(q["id"]) == selected_question]
    
    # æ˜¾ç¤ºé¢˜ç›®
    for question in filtered_questions:
        dim_class = f"dim-{question['dimension']}"
        dim_name = DIMENSION_NAMES.get(question['dimension'], question['dimension'])
        dim_icon = DIMENSION_ICONS.get(question['dimension'], 'ğŸ“Œ')
        
        with st.expander(f"**ç¬¬ {question['id']} é¢˜**: {question['title']}", expanded=(selected_question != "å…¨éƒ¨")):
            # é¢˜ç›®ä¿¡æ¯
            st.markdown(f"""
            <div style="display: flex; gap: 0.5rem; margin-bottom: 1rem;">
                <span class="dimension-badge {dim_class}">{dim_icon} {dim_name}</span>
                <span class="dimension-badge" style="background: #475569;">éš¾åº¦: {question.get('difficulty', 'N/A')}</span>
                <span class="dimension-badge" style="background: #475569;">ç±»å‹: {question.get('type', 'N/A')}</span>
            </div>
            """, unsafe_allow_html=True)
            
            # é¢˜ç›®å†…å®¹
            st.markdown("#### ğŸ“‹ é¢˜ç›®å†…å®¹")
            st.markdown(f"""
            <div style="background: #0f172a; border: 1px solid #334155; border-radius: 8px; padding: 1rem; margin: 0.5rem 0;">
                <pre style="white-space: pre-wrap; word-wrap: break-word; color: #e2e8f0; margin: 0; font-family: 'Noto Sans SC', sans-serif;">{question['content']}</pre>
            </div>
            """, unsafe_allow_html=True)
            
            # å¤åˆ¶æŒ‰é’®
            if st.button(f"ğŸ“‹ å¤åˆ¶é¢˜ç›®åˆ°å‰ªè´´æ¿", key=f"copy_{question['id']}"):
                st.code(question['content'], language=None)
                st.info("ğŸ‘† è¯·æ‰‹åŠ¨é€‰æ‹©ä¸Šæ–¹æ–‡æœ¬å¹¶å¤åˆ¶ (Ctrl+C)")
            
            st.markdown("---")
            
            # é€‰æ‹©æ¨¡å‹å¹¶å¡«å†™ç­”æ¡ˆ
            st.markdown("#### âœï¸ å¡«å†™æ¨¡å‹ç­”æ¡ˆ")
            
            if selected_model != "å…¨éƒ¨":
                target_models = [m for m in models_data["models"] if m["name"] == selected_model]
            else:
                target_models = models_data["models"]
            
            for model in target_models:
                existing_answer = get_answer(question['id'], model['id'])
                
                with st.container():
                    col_a, col_b = st.columns([3, 1])
                    with col_a:
                        st.markdown(f"**{model['icon']} {model['name']}** ([å‰å¾€å®˜ç½‘]({model['url']}))")
                    with col_b:
                        if existing_answer and existing_answer.get('score') is not None:
                            score = existing_answer['score']
                            st.markdown(f"<span class='score-badge score-{score}'>{score}åˆ†</span>", unsafe_allow_html=True)
                    
                    default_value = existing_answer['answer'] if existing_answer else ""
                    answer_text = st.text_area(
                        f"å›ç­”å†…å®¹",
                        value=default_value,
                        height=150,
                        key=f"answer_{question['id']}_{model['id']}",
                        placeholder=f"å°† {model['name']} çš„å›ç­”ç²˜è´´åˆ°è¿™é‡Œ..."
                    )
                    
                    col1, col2 = st.columns([1, 4])
                    with col1:
                        if st.button("ğŸ’¾ ä¿å­˜", key=f"save_{question['id']}_{model['id']}"):
                            if answer_text.strip():
                                save_answer(question['id'], model['id'], answer_text.strip())
                                st.success("âœ… å·²ä¿å­˜!")
                                st.rerun()
                            else:
                                st.warning("âš ï¸ ç­”æ¡ˆä¸èƒ½ä¸ºç©º")
                    
                    with col2:
                        if existing_answer:
                            st.caption(f"ğŸ“… ä¸Šæ¬¡æ›´æ–°: {existing_answer['timestamp'][:19]}")
                    
                    st.markdown("---")


def render_scoring():
    """æ¸²æŸ“è¯„åˆ†æ‰“åˆ†é¡µé¢"""
    st.markdown('<h1 class="main-title">â­ è¯„åˆ†æ‰“åˆ†</h1>', unsafe_allow_html=True)
    
    questions_data = load_json(QUESTIONS_FILE)
    models_data = load_json(MODELS_FILE)
    rubric_data = load_json(SCORING_RUBRIC_FILE)
    
    if not questions_data or not models_data:
        st.error("æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶")
        return
    
    # ç­›é€‰å™¨
    col1, col2, col3 = st.columns(3)
    
    with col1:
        model_options = [m["name"] for m in models_data["models"]]
        selected_model_name = st.selectbox("ğŸ¤– é€‰æ‹©æ¨¡å‹", model_options)
        selected_model = next((m for m in models_data["models"] if m["name"] == selected_model_name), None)
    
    with col2:
        filter_options = ["å…¨éƒ¨", "æœªè¯„åˆ†", "å·²è¯„åˆ†"]
        filter_status = st.selectbox("ğŸ“Š ç­›é€‰çŠ¶æ€", filter_options)
    
    with col3:
        question_ids = ["å…¨éƒ¨"] + [str(q["id"]) for q in questions_data["questions"]]
        selected_question = st.selectbox("ğŸ“‹ é€‰æ‹©é¢˜å·", question_ids)
    
    if not selected_model:
        return
    
    st.markdown("---")
    
    # è¯„åˆ†è¿›åº¦
    model_scores = get_model_scores(selected_model["id"])
    scored_count = len(model_scores)
    total_score = sum(model_scores.values())
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("å·²è¯„åˆ†é¢˜ç›®", f"{scored_count}/{TOTAL_QUESTIONS}")
    with col2:
        st.metric("å½“å‰æ€»åˆ†", f"{total_score}/{MAX_TOTAL_SCORE}")
    with col3:
        avg_score = total_score / scored_count if scored_count > 0 else 0
        st.metric("å¹³å‡åˆ†", f"{avg_score:.2f}")
    
    st.markdown("---")
    
    # éå†é¢˜ç›®è¿›è¡Œè¯„åˆ†
    for question in questions_data["questions"]:
        if selected_question != "å…¨éƒ¨" and str(question["id"]) != selected_question:
            continue
        
        answer = get_answer(question["id"], selected_model["id"])
        
        # æ ¹æ®ç­›é€‰çŠ¶æ€è¿‡æ»¤
        if filter_status == "æœªè¯„åˆ†" and (answer and answer.get("score") is not None):
            continue
        if filter_status == "å·²è¯„åˆ†" and (not answer or answer.get("score") is None):
            continue
        
        if not answer:
            continue
        
        dim_name = DIMENSION_NAMES.get(question['dimension'], question['dimension'])
        current_score = answer.get("score")
        
        with st.expander(
            f"**ç¬¬ {question['id']} é¢˜** - {question['title']} " + 
            (f"[{current_score}åˆ†]" if current_score is not None else "[æœªè¯„åˆ†]"),
            expanded=(selected_question != "å…¨éƒ¨")
        ):
            # æ˜¾ç¤ºé¢˜ç›®
            st.markdown(f"**ç»´åº¦**: {dim_name}")
            
            with st.container():
                st.markdown("**ğŸ“‹ é¢˜ç›®å†…å®¹** (ç‚¹å‡»å±•å¼€)")
                with st.expander("æŸ¥çœ‹é¢˜ç›®", expanded=False):
                    st.text(question['content'][:500] + "..." if len(question['content']) > 500 else question['content'])
            
            # æ˜¾ç¤ºç­”æ¡ˆ
            st.markdown("**ğŸ“ æ¨¡å‹ç­”æ¡ˆ**")
            st.markdown(f"""
            <div class="answer-preview" style="max-height: 300px;">
                {answer['answer'][:2000]}{"..." if len(answer['answer']) > 2000 else ""}
            </div>
            """, unsafe_allow_html=True)
            
            # æ˜¾ç¤ºå·²æœ‰è¯„åˆ†è¯¦æƒ…ï¼ˆå¦‚æœæ˜¯è‡ªåŠ¨è¯„åˆ†çš„ï¼‰
            if answer.get("scored_by") == "deepseek-auto":
                st.markdown("**ğŸ¤– AIè‡ªåŠ¨è¯„åˆ†è¯¦æƒ…**")
                col_s1, col_s2 = st.columns(2)
                with col_s1:
                    st.success(f"âœ… ä¼˜ç‚¹: {answer.get('strengths', 'N/A')}")
                with col_s2:
                    st.warning(f"âš ï¸ ä¸è¶³: {answer.get('weaknesses', 'N/A')}")
                if answer.get("comment"):
                    st.info(f"ğŸ’¬ è¯„è¯­: {answer.get('comment', '')}")
            
            # æ˜¾ç¤ºè¯„åˆ†æ ‡å‡†
            if rubric_data:
                q_rubric = next((q for q in rubric_data["questions"] if q["id"] == question["id"]), None)
                if q_rubric:
                    with st.expander("ğŸ“– è¯„åˆ†æ ‡å‡†", expanded=False):
                        st.json(q_rubric.get("scoring_criteria", {}))
            
            # è¯„åˆ†è¾“å…¥
            st.markdown("---")
            col1, col2 = st.columns([1, 2])
            
            with col1:
                score = st.selectbox(
                    "è¯„åˆ† (0-5åˆ†)",
                    options=[None, 5, 4, 3, 2, 1, 0],
                    format_func=lambda x: "è¯·é€‰æ‹©" if x is None else f"{x}åˆ†",
                    index=0 if current_score is None else [None, 5, 4, 3, 2, 1, 0].index(current_score),
                    key=f"score_{question['id']}_{selected_model['id']}"
                )
            
            with col2:
                comment = st.text_input(
                    "è¯„è¯­ (å¯é€‰)",
                    value=answer.get("comment", "") or "",
                    key=f"comment_{question['id']}_{selected_model['id']}"
                )
            
            if st.button("ğŸ’¾ ä¿å­˜è¯„åˆ†", key=f"save_score_{question['id']}_{selected_model['id']}"):
                if score is not None:
                    save_score(question['id'], selected_model['id'], score, comment)
                    st.success(f"âœ… å·²ä¿å­˜è¯„åˆ†: {score}åˆ†")
                    st.rerun()
                else:
                    st.warning("âš ï¸ è¯·é€‰æ‹©è¯„åˆ†")


def render_results():
    """æ¸²æŸ“ç»“æœå±•ç¤ºé¡µé¢"""
    st.markdown('<h1 class="main-title">ğŸ“Š ç»“æœå±•ç¤º</h1>', unsafe_allow_html=True)
    
    questions_data = load_json(QUESTIONS_FILE)
    models_data = load_json(MODELS_FILE)
    all_scores = get_all_scores()
    
    if not questions_data or not models_data:
        st.error("æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶")
        return
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¯„åˆ†æ•°æ®
    has_scores = any(s["scored"] > 0 for s in all_scores.values())
    
    if not has_scores:
        st.warning("âš ï¸ æš‚æ— è¯„åˆ†æ•°æ®ï¼Œè¯·å…ˆåœ¨ã€Œè¯„åˆ†æ‰“åˆ†ã€é¡µé¢è¿›è¡Œè¯„åˆ†")
        return
    
    # é€‰æ‹©å±•ç¤ºæ–¹å¼
    view_type = st.selectbox(
        "ğŸ“Š é€‰æ‹©å±•ç¤ºæ–¹å¼",
        ["ğŸ† æ€»åˆ†æ’è¡Œæ¦œ", "ğŸ“ˆ ç»´åº¦å¯¹æ¯”", "ğŸ¯ é›·è¾¾å›¾", "ğŸ“‹ è¯¦ç»†å¾—åˆ†è¡¨", "ğŸ“‰ å¾—åˆ†åˆ†å¸ƒ", "ğŸ” é¢˜ç›®æ¨ªå‘å¯¹æ¯”"]
    )
    
    st.markdown("---")
    
    if view_type == "ğŸ† æ€»åˆ†æ’è¡Œæ¦œ":
        render_leaderboard(all_scores, models_data)
    elif view_type == "ğŸ“ˆ ç»´åº¦å¯¹æ¯”":
        render_dimension_comparison(all_scores, questions_data, models_data)
    elif view_type == "ğŸ¯ é›·è¾¾å›¾":
        render_radar_chart(all_scores, questions_data, models_data)
    elif view_type == "ğŸ“‹ è¯¦ç»†å¾—åˆ†è¡¨":
        render_score_table(all_scores, questions_data, models_data)
    elif view_type == "ğŸ“‰ å¾—åˆ†åˆ†å¸ƒ":
        render_score_distribution(all_scores, questions_data, models_data)
    elif view_type == "ğŸ” é¢˜ç›®æ¨ªå‘å¯¹æ¯”":
        render_question_comparison(questions_data, models_data)


def render_leaderboard(all_scores, models_data):
    """æ¸²æŸ“æ€»åˆ†æ’è¡Œæ¦œ"""
    st.markdown("### ğŸ† æ€»åˆ†æ’è¡Œæ¦œ")
    
    # å‡†å¤‡æ’è¡Œæ•°æ®
    leaderboard = []
    for model_id, data in all_scores.items():
        if data["scored"] > 0:
            leaderboard.append({
                "model_id": model_id,
                "name": data["name"],
                "icon": data["icon"],
                "total": data["total"],
                "scored": data["scored"],
                "max_possible": data["scored"] * SCORE_PER_QUESTION,
                "percentage": (data["total"] / (data["scored"] * SCORE_PER_QUESTION) * 100) if data["scored"] > 0 else 0
            })
    
    # æŒ‰æ€»åˆ†æ’åº
    leaderboard.sort(key=lambda x: x["total"], reverse=True)
    
    # æ˜¾ç¤ºæ’è¡Œæ¦œ
    for rank, item in enumerate(leaderboard, 1):
        rank_class = f"rank-{rank}" if rank <= 3 else ""
        medal = "ğŸ¥‡" if rank == 1 else ("ğŸ¥ˆ" if rank == 2 else ("ğŸ¥‰" if rank == 3 else f"#{rank}"))
        
        col1, col2, col3, col4 = st.columns([1, 3, 2, 2])
        
        with col1:
            st.markdown(f"### {medal}")
        with col2:
            st.markdown(f"### {item['icon']} {item['name']}")
        with col3:
            st.markdown(f"### **{item['total']}** / {MAX_TOTAL_SCORE}")
        with col4:
            st.progress(item['percentage'] / 100)
            st.caption(f"{item['percentage']:.1f}% ({item['scored']}é¢˜å·²è¯„)")
        
        st.markdown("---")
    
    # æŸ±çŠ¶å›¾
    if leaderboard:
        fig = px.bar(
            leaderboard,
            x="name",
            y="total",
            color="total",
            color_continuous_scale="Viridis",
            title="æ¨¡å‹å¾—åˆ†å¯¹æ¯”",
            labels={"name": "æ¨¡å‹", "total": "æ€»åˆ†"}
        )
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='#f1f5f9'
        )
        st.plotly_chart(fig, use_container_width=True)


def render_dimension_comparison(all_scores, questions_data, models_data):
    """æ¸²æŸ“ç»´åº¦å¯¹æ¯”"""
    st.markdown("### ğŸ“ˆ ç»´åº¦å¯¹æ¯”")
    
    # è®¡ç®—æ¯ä¸ªæ¨¡å‹åœ¨æ¯ä¸ªç»´åº¦çš„å¾—åˆ†
    dimension_scores = {}
    
    for dim in questions_data["meta"]["dimensions"]:
        dim_id = dim["id"]
        dim_questions = dim["questions"]
        dimension_scores[dim_id] = {"name": dim["name"], "questions": dim_questions, "scores": {}}
        
        for model_id, data in all_scores.items():
            dim_total = 0
            dim_count = 0
            for q_id in dim_questions:
                if q_id in data["scores"]:
                    dim_total += data["scores"][q_id]
                    dim_count += 1
            
            if dim_count > 0:
                dimension_scores[dim_id]["scores"][model_id] = {
                    "total": dim_total,
                    "count": dim_count,
                    "max": dim_count * SCORE_PER_QUESTION,
                    "percentage": dim_total / (dim_count * SCORE_PER_QUESTION) * 100
                }
    
    # åˆ›å»ºæ•°æ®æ¡†
    data_rows = []
    for dim_id, dim_data in dimension_scores.items():
        for model_id, score_data in dim_data["scores"].items():
            model_name = all_scores[model_id]["name"]
            data_rows.append({
                "ç»´åº¦": dim_data["name"],
                "æ¨¡å‹": model_name,
                "å¾—åˆ†": score_data["total"],
                "æ»¡åˆ†": score_data["max"],
                "å¾—åˆ†ç‡": score_data["percentage"]
            })
    
    if data_rows:
        df = pd.DataFrame(data_rows)
        
        # åˆ†ç»„æŸ±çŠ¶å›¾
        fig = px.bar(
            df,
            x="ç»´åº¦",
            y="å¾—åˆ†ç‡",
            color="æ¨¡å‹",
            barmode="group",
            title="å„ç»´åº¦å¾—åˆ†ç‡å¯¹æ¯”",
            labels={"å¾—åˆ†ç‡": "å¾—åˆ†ç‡ (%)"}
        )
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='#f1f5f9'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # çƒ­åŠ›å›¾
        pivot_df = df.pivot(index="æ¨¡å‹", columns="ç»´åº¦", values="å¾—åˆ†ç‡")
        fig_heat = px.imshow(
            pivot_df,
            color_continuous_scale="RdYlGn",
            title="å¾—åˆ†ç‡çƒ­åŠ›å›¾",
            labels={"color": "å¾—åˆ†ç‡ (%)"}
        )
        fig_heat.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='#f1f5f9'
        )
        st.plotly_chart(fig_heat, use_container_width=True)


def render_radar_chart(all_scores, questions_data, models_data):
    """æ¸²æŸ“é›·è¾¾å›¾"""
    st.markdown("### ğŸ¯ èƒ½åŠ›é›·è¾¾å›¾")
    
    # é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹
    available_models = [m["name"] for m_id, m in all_scores.items() if m["scored"] > 0 for m in [all_scores[m_id]]]
    available_models = list(set(available_models))
    
    selected_models = st.multiselect(
        "é€‰æ‹©è¦å¯¹æ¯”çš„æ¨¡å‹",
        available_models,
        default=available_models[:3] if len(available_models) >= 3 else available_models
    )
    
    if not selected_models:
        st.warning("è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹")
        return
    
    # è®¡ç®—æ¯ä¸ªç»´åº¦çš„å¾—åˆ†
    categories = [dim["name"] for dim in questions_data["meta"]["dimensions"]]
    
    fig = go.Figure()
    
    for model_name in selected_models:
        model_id = next((m_id for m_id, m in all_scores.items() if m["name"] == model_name), None)
        if not model_id:
            continue
        
        values = []
        for dim in questions_data["meta"]["dimensions"]:
            dim_total = 0
            dim_count = 0
            for q_id in dim["questions"]:
                if q_id in all_scores[model_id]["scores"]:
                    dim_total += all_scores[model_id]["scores"][q_id]
                    dim_count += 1
            
            if dim_count > 0:
                values.append(dim_total / (dim_count * SCORE_PER_QUESTION) * 100)
            else:
                values.append(0)
        
        # é—­åˆé›·è¾¾å›¾
        values.append(values[0])
        cats = categories + [categories[0]]
        
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=cats,
            fill='toself',
            name=model_name
        ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100]
            )
        ),
        showlegend=True,
        title="æ¨¡å‹èƒ½åŠ›é›·è¾¾å›¾",
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font_color='#f1f5f9'
    )
    
    st.plotly_chart(fig, use_container_width=True)


def render_score_table(all_scores, questions_data, models_data):
    """æ¸²æŸ“è¯¦ç»†å¾—åˆ†è¡¨"""
    st.markdown("### ğŸ“‹ è¯¦ç»†å¾—åˆ†è¡¨")
    
    # æ„å»ºè¡¨æ ¼æ•°æ®
    headers = ["é¢˜å·", "ç»´åº¦"] + [m["name"] for m in models_data["models"] if m["id"] in all_scores]
    
    rows = []
    for question in questions_data["questions"]:
        row = [
            f"Q{question['id']}",
            DIMENSION_NAMES.get(question['dimension'], question['dimension'])
        ]
        
        for model in models_data["models"]:
            if model["id"] in all_scores:
                score = all_scores[model["id"]]["scores"].get(question["id"])
                row.append(score if score is not None else "-")
        
        rows.append(row)
    
    # æ·»åŠ æ€»åˆ†è¡Œ
    total_row = ["æ€»åˆ†", "-"]
    for model in models_data["models"]:
        if model["id"] in all_scores:
            total_row.append(all_scores[model["id"]]["total"])
    rows.append(total_row)
    
    df = pd.DataFrame(rows, columns=headers)
    
    # æ ·å¼åŒ–æ˜¾ç¤º
    def color_score(val):
        if val == "-":
            return "background-color: #475569"
        if isinstance(val, (int, float)):
            if val >= 4:
                return "background-color: #22c55e; color: white"
            elif val >= 3:
                return "background-color: #eab308; color: black"
            elif val >= 2:
                return "background-color: #f97316; color: white"
            else:
                return "background-color: #ef4444; color: white"
        return ""
    
    st.dataframe(df, use_container_width=True, height=600)


def render_score_distribution(all_scores, questions_data, models_data):
    """æ¸²æŸ“å¾—åˆ†åˆ†å¸ƒ"""
    st.markdown("### ğŸ“‰ å¾—åˆ†åˆ†å¸ƒ")
    
    # æ”¶é›†æ‰€æœ‰è¯„åˆ†
    all_individual_scores = []
    for model_id, data in all_scores.items():
        for q_id, score in data["scores"].items():
            all_individual_scores.append({
                "æ¨¡å‹": data["name"],
                "é¢˜å·": f"Q{q_id}",
                "å¾—åˆ†": score
            })
    
    if not all_individual_scores:
        st.warning("æš‚æ— è¯„åˆ†æ•°æ®")
        return
    
    df = pd.DataFrame(all_individual_scores)
    
    # å¾—åˆ†åˆ†å¸ƒç›´æ–¹å›¾
    fig = px.histogram(
        df,
        x="å¾—åˆ†",
        color="æ¨¡å‹",
        barmode="overlay",
        title="å¾—åˆ†åˆ†å¸ƒ",
        labels={"å¾—åˆ†": "å¾—åˆ†", "count": "æ•°é‡"}
    )
    fig.update_layout(
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font_color='#f1f5f9'
    )
    st.plotly_chart(fig, use_container_width=True)
    
    # ç®±çº¿å›¾
    fig_box = px.box(
        df,
        x="æ¨¡å‹",
        y="å¾—åˆ†",
        color="æ¨¡å‹",
        title="å¾—åˆ†ç®±çº¿å›¾"
    )
    fig_box.update_layout(
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font_color='#f1f5f9'
    )
    st.plotly_chart(fig_box, use_container_width=True)


def render_question_comparison(questions_data, models_data):
    """æ¸²æŸ“é¢˜ç›®æ¨ªå‘å¯¹æ¯”"""
    st.markdown("### ğŸ” é¢˜ç›®æ¨ªå‘å¯¹æ¯”")
    st.markdown("æ¯”è¾ƒå„æ¨¡å‹åœ¨åŒä¸€é“é¢˜ä¸Šçš„è¡¨ç°")
    
    # é€‰æ‹©é¢˜ç›®
    question_options = [f"Q{q['id']}: {q['title']}" for q in questions_data["questions"]]
    selected = st.selectbox("é€‰æ‹©é¢˜ç›®", question_options)
    
    if not selected:
        return
    
    q_id = int(selected.split(":")[0].replace("Q", ""))
    question = next((q for q in questions_data["questions"] if q["id"] == q_id), None)
    
    if not question:
        return
    
    # æ˜¾ç¤ºé¢˜ç›®ä¿¡æ¯
    st.markdown(f"**ç»´åº¦**: {DIMENSION_NAMES.get(question['dimension'], question['dimension'])}")
    st.markdown(f"**éš¾åº¦**: {question.get('difficulty', 'N/A')}")
    
    with st.expander("ğŸ“‹ æŸ¥çœ‹é¢˜ç›®å†…å®¹", expanded=False):
        st.text(question['content'])
    
    st.markdown("---")
    
    # è·å–æ‰€æœ‰æ¨¡å‹å¯¹è¯¥é¢˜çš„å›ç­”å’Œè¯„åˆ†
    answers_data = load_answers()
    model_answers = []
    
    for model in models_data["models"]:
        ans = get_answer(q_id, model["id"])
        if ans:
            model_answers.append({
                "model_id": model["id"],
                "model_name": model["name"],
                "model_icon": model["icon"],
                "answer": ans["answer"],
                "score": ans.get("score"),
                "comment": ans.get("comment", ""),
                "strengths": ans.get("strengths", ""),
                "weaknesses": ans.get("weaknesses", ""),
                "scored_by": ans.get("scored_by", "")
            })
    
    if not model_answers:
        st.warning("æš‚æ— è¯¥é¢˜çš„å›ç­”")
        return
    
    # æŒ‰å¾—åˆ†æ’åº
    model_answers.sort(key=lambda x: x["score"] if x["score"] is not None else -1, reverse=True)
    
    # æ˜¾ç¤ºæ’å
    st.markdown("#### ğŸ“Š å¾—åˆ†æ’å")
    
    for rank, ma in enumerate(model_answers, 1):
        medal = "ğŸ¥‡" if rank == 1 else ("ğŸ¥ˆ" if rank == 2 else ("ğŸ¥‰" if rank == 3 else f"#{rank}"))
        score_display = f"{ma['score']}/5" if ma['score'] is not None else "æœªè¯„åˆ†"
        
        with st.expander(f"{medal} {ma['model_icon']} {ma['model_name']} - **{score_display}**", expanded=(rank <= 3)):
            # è¯„åˆ†è¯¦æƒ…
            if ma['score'] is not None:
                col1, col2, col3 = st.columns(3)
                with col1:
                    score_color = ["#ef4444", "#ef4444", "#f97316", "#eab308", "#84cc16", "#22c55e"][ma['score']]
                    st.markdown(f"""
                    <div style="text-align:center; padding:1rem; background:{score_color}; border-radius:8px;">
                        <div style="font-size:2rem; font-weight:bold; color:white;">{ma['score']}</div>
                        <div style="color:white;">å¾—åˆ†</div>
                    </div>
                    """, unsafe_allow_html=True)
                with col2:
                    if ma.get('strengths'):
                        st.success(f"âœ… {ma['strengths']}")
                with col3:
                    if ma.get('weaknesses'):
                        st.warning(f"âš ï¸ {ma['weaknesses']}")
                
                if ma.get('comment'):
                    st.info(f"ğŸ’¬ {ma['comment']}")
                
                if ma.get('scored_by') == 'deepseek-auto':
                    st.caption("ğŸ¤– ç”± DeepSeek è‡ªåŠ¨è¯„åˆ†")
            
            # æ˜¾ç¤ºå›ç­”
            st.markdown("**å›ç­”å†…å®¹:**")
            st.markdown(f"""
            <div class="answer-preview" style="max-height:300px; overflow-y:auto;">
                {ma['answer'][:3000]}{"..." if len(ma['answer']) > 3000 else ""}
            </div>
            """, unsafe_allow_html=True)
    
    # å¯¹æ¯”å›¾è¡¨
    if any(ma['score'] is not None for ma in model_answers):
        st.markdown("---")
        st.markdown("#### ğŸ“ˆ å¾—åˆ†å¯¹æ¯”å›¾")
        
        chart_data = [
            {"æ¨¡å‹": ma['model_name'], "å¾—åˆ†": ma['score'] or 0}
            for ma in model_answers
        ]
        
        fig = px.bar(
            chart_data,
            x="æ¨¡å‹",
            y="å¾—åˆ†",
            color="å¾—åˆ†",
            color_continuous_scale="RdYlGn",
            range_color=[0, 5],
            title=f"Q{q_id} å„æ¨¡å‹å¾—åˆ†å¯¹æ¯”"
        )
        fig.update_layout(
            plot_bgcolor='rgba(0,0,0,0)',
            paper_bgcolor='rgba(0,0,0,0)',
            font_color='#f1f5f9',
            yaxis_range=[0, 5.5]
        )
        st.plotly_chart(fig, use_container_width=True)


def render_data_view():
    """æ¸²æŸ“æ•°æ®æŸ¥çœ‹é¡µé¢"""
    st.markdown('<h1 class="main-title">ğŸ“‹ æ•°æ®æŸ¥çœ‹</h1>', unsafe_allow_html=True)
    
    questions_data = load_json(QUESTIONS_FILE)
    models_data = load_json(MODELS_FILE)
    answers_data = load_answers()
    
    if not questions_data or not models_data:
        st.error("æ— æ³•åŠ è½½æ•°æ®æ–‡ä»¶")
        return
    
    # æ•°æ®æ¦‚è§ˆ
    st.markdown("### ğŸ“ˆ æ•°æ®æ¦‚è§ˆ")
    
    # æ„å»ºå®Œæˆåº¦çŸ©é˜µ
    completion_matrix = {}
    for model in models_data["models"]:
        completion_matrix[model["id"]] = {}
        for question in questions_data["questions"]:
            answer = get_answer(question["id"], model["id"])
            if answer:
                score = answer.get("score")
                if score is not None:
                    completion_matrix[model["id"]][question["id"]] = f"âœ…{score}"
                else:
                    completion_matrix[model["id"]][question["id"]] = "ğŸ“"
            else:
                completion_matrix[model["id"]][question["id"]] = "âŒ"
    
    # æ˜¾ç¤ºçŸ©é˜µ
    st.markdown("#### ğŸ“‹ ç­”æ¡ˆä¸è¯„åˆ†çŠ¶æ€çŸ©é˜µ")
    st.caption("âœ…å·²è¯„åˆ† | ğŸ“æœ‰ç­”æ¡ˆæœªè¯„åˆ† | âŒæ— ç­”æ¡ˆ")
    
    # æ„å»ºè¡¨æ ¼HTML
    header_cells = "<th>æ¨¡å‹</th>" + "".join([f"<th>Q{q['id']}</th>" for q in questions_data["questions"]])
    
    rows = []
    for model in models_data["models"]:
        row_cells = f"<td><strong>{model['icon']} {model['name']}</strong></td>"
        for question in questions_data["questions"]:
            status = completion_matrix[model["id"]][question["id"]]
            row_cells += f"<td style='text-align: center;'>{status}</td>"
        rows.append(f"<tr>{row_cells}</tr>")
    
    table_html = f"""
    <div style="overflow-x: auto;">
        <table style="width: 100%; border-collapse: collapse; background: #1e293b; border-radius: 8px;">
            <thead style="background: #334155;">
                <tr>{header_cells}</tr>
            </thead>
            <tbody>
                {"".join(rows)}
            </tbody>
        </table>
    </div>
    """
    st.markdown(table_html, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # æŒ‰é¢˜ç›®æŸ¥çœ‹ç­”æ¡ˆå¯¹æ¯”
    st.markdown("### ğŸ” ç­”æ¡ˆå¯¹æ¯”")
    
    question_options = [f"Q{q['id']}: {q['title']}" for q in questions_data["questions"]]
    selected = st.selectbox("é€‰æ‹©é¢˜ç›®", question_options)
    
    if selected:
        q_id = int(selected.split(":")[0].replace("Q", ""))
        question = next((q for q in questions_data["questions"] if q["id"] == q_id), None)
        
        if question:
            st.markdown(f"**é¢˜ç›®å†…å®¹**: {question['content'][:200]}..." if len(question['content']) > 200 else f"**é¢˜ç›®å†…å®¹**: {question['content']}")
            
            st.markdown("---")
            
            cols = st.columns(2)
            for idx, model in enumerate(models_data["models"]):
                with cols[idx % 2]:
                    answer = get_answer(q_id, model["id"])
                    score_badge = ""
                    if answer and answer.get("score") is not None:
                        score = answer["score"]
                        score_badge = f" <span class='score-badge score-{score}'>{score}åˆ†</span>"
                    
                    st.markdown(f"#### {model['icon']} {model['name']}{score_badge}", unsafe_allow_html=True)
                    if answer:
                        st.markdown(f"""
                        <div class="answer-preview">
                            {answer['answer'][:500]}{"..." if len(answer['answer']) > 500 else ""}
                        </div>
                        """, unsafe_allow_html=True)
                        st.caption(f"ğŸ“… {answer['timestamp'][:19]}")
                    else:
                        st.info("æš‚æ— ç­”æ¡ˆ")
    
    st.markdown("---")
    
    # å¯¼å‡ºåŠŸèƒ½
    st.markdown("### ğŸ“¤ æ•°æ®å¯¼å‡º")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ“¥ å¯¼å‡ºæ‰€æœ‰ç­”æ¡ˆ (JSON)"):
            st.download_button(
                label="ä¸‹è½½ answers.json",
                data=json.dumps(answers_data, ensure_ascii=False, indent=2),
                file_name="answers_export.json",
                mime="application/json"
            )
    
    with col2:
        if st.button("ğŸ“¥ å¯¼å‡ºè¯„åˆ†ç»“æœ (CSV)"):
            # å‡†å¤‡CSVæ•°æ®
            csv_rows = []
            for ans in answers_data["answers"]:
                csv_rows.append({
                    "question_id": ans["question_id"],
                    "model_id": ans["model_id"],
                    "score": ans.get("score", ""),
                    "comment": ans.get("comment", ""),
                    "timestamp": ans.get("timestamp", "")
                })
            
            if csv_rows:
                df = pd.DataFrame(csv_rows)
                st.download_button(
                    label="ä¸‹è½½ scores.csv",
                    data=df.to_csv(index=False),
                    file_name="scores_export.csv",
                    mime="text/csv"
                )


def render_settings():
    """æ¸²æŸ“è®¾ç½®é¡µé¢"""
    st.markdown('<h1 class="main-title">âš™ï¸ è®¾ç½®</h1>', unsafe_allow_html=True)
    
    st.markdown("### ğŸ“ æ•°æ®ç®¡ç†")
    
    # æ˜¾ç¤ºæ–‡ä»¶çŠ¶æ€
    files = [
        ("questions.json", QUESTIONS_FILE),
        ("models.json", MODELS_FILE),
        ("answers.json", ANSWERS_FILE),
        ("scoring_rubric.json", SCORING_RUBRIC_FILE)
    ]
    
    for name, path in files:
        exists = os.path.exists(path)
        size = os.path.getsize(path) if exists else 0
        status = "âœ… å­˜åœ¨" if exists else "âŒ ä¸å­˜åœ¨"
        st.markdown(f"- **{name}**: {status} ({size/1024:.1f} KB)")
    
    st.markdown("---")
    
    st.markdown("### ğŸ”„ é‡ç½®æ•°æ®")
    
    st.warning("âš ï¸ ä»¥ä¸‹æ“ä½œä¸å¯é€†ï¼Œè¯·è°¨æ…æ“ä½œï¼")
    
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰ç­”æ¡ˆ", type="secondary"):
            confirm = st.checkbox("ç¡®è®¤æ¸…ç©ºæ‰€æœ‰ç­”æ¡ˆæ•°æ®", key="confirm_clear_answers")
            if confirm:
                empty_data = {
                    "meta": {
                        "title": "æ¨¡å‹å›ç­”è®°å½•",
                        "version": "1.0",
                        "created_at": datetime.now().isoformat(),
                        "last_updated": datetime.now().isoformat()
                    },
                    "answers": []
                }
                save_json(ANSWERS_FILE, empty_data)
                st.success("âœ… å·²æ¸…ç©ºæ‰€æœ‰ç­”æ¡ˆ!")
                st.rerun()
    
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰è¯„åˆ†", type="secondary"):
            confirm = st.checkbox("ç¡®è®¤æ¸…ç©ºæ‰€æœ‰è¯„åˆ†æ•°æ®", key="confirm_clear_scores")
            if confirm:
                answers_data = load_answers()
                for ans in answers_data["answers"]:
                    ans["score"] = None
                    ans["comment"] = None
                    if "scored_at" in ans:
                        del ans["scored_at"]
                save_json(ANSWERS_FILE, answers_data)
                st.success("âœ… å·²æ¸…ç©ºæ‰€æœ‰è¯„åˆ†!")
                st.rerun()
    
    st.markdown("---")
    
    st.markdown("### â„¹ï¸ å…³äº")
    st.markdown(f"""
    **LLM æµ‹è¯„å¹³å°** v2.0
    
    ç”¨äºæµ‹è¯•å’Œæ¯”è¾ƒä¸åŒå¤§è¯­è¨€æ¨¡å‹åœ¨å„ç»´åº¦ä¸Šçš„è¡¨ç°ã€‚
    
    - ğŸ“ {TOTAL_QUESTIONS}é“æµ‹è¯„é¢˜ç›®
    - ğŸ¤– å¤šä¸ªä¸»æµå¤§è¯­è¨€æ¨¡å‹
    - â­ æ¯é¢˜{SCORE_PER_QUESTION}åˆ†ï¼Œæ€»åˆ†{MAX_TOTAL_SCORE}åˆ†
    - ğŸ“Š å¤šç»´åº¦å¯è§†åŒ–åˆ†æ
    - ğŸ’¾ JSONæ•°æ®æŒä¹…åŒ–
    """)


def main():
    """ä¸»å‡½æ•°"""
    page = render_sidebar()
    
    if page == "ğŸ  é¦–é¡µ":
        render_home()
    elif page == "ğŸ“ é¢˜ç›®æµ‹è¯„":
        render_questions()
    elif page == "â­ è¯„åˆ†æ‰“åˆ†":
        render_scoring()
    elif page == "ğŸ“Š ç»“æœå±•ç¤º":
        render_results()
    elif page == "ğŸ“‹ æ•°æ®æŸ¥çœ‹":
        render_data_view()
    elif page == "âš™ï¸ è®¾ç½®":
        render_settings()


if __name__ == "__main__":
    main()
